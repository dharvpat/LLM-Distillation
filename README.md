**Model Distillation**

This repository contains a Jupyter Notebook that demonstrates the process of model distillationâ€”a technique for compressing a large, complex model into a smaller, more efficient one without sacrificing much performance.

Overview:
Model distillation transfers knowledge from a "teacher" model to a "student" model. This notebook provides a step-by-step guide, complete with code examples and explanations, to help you understand and implement model distillation in your own projects.

Instructions to Use:
- Pretty simple, easy to follow python noptebook
- Problematic packages include bitsandbytes, transformers, accelerate, make sure the versions you have are compatible with each other.

 *Not Intended for commercial use*
